{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "\n",
    "import torch_geometric\n",
    "import torch_geometric.nn as pyg_nn\n",
    "from torch_geometric.utils import to_networkx\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.datasets import Entities\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.utils import k_hop_subgraph\n",
    "\n",
    "\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib as mpl\n",
    "import plotly.express as px\n",
    "\n",
    "import seaborn as sns\n",
    "from functools import partial\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "import collections\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger, WandbLogger\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "pl.seed_everything(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 AM dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetAM = Entities(name='AM', root='data/am')\n",
    "dataAM = datasetAM[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDGE TYPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265])\n",
      "266\n",
      "tensor([ 2,  6,  2,  0,  2,  5, 10,  7,  2,  4,  2,  1,  1,  2,  4,  7,  2,  3,\n",
      "         2,  1,  0,  6,  9,  5,  1,  9,  3,  5,  2,  4,  5,  0,  2,  2,  0,  0,\n",
      "         2,  0,  1,  2,  9,  2,  4,  7,  5,  6,  2,  7,  9,  2,  6,  2,  6,  9,\n",
      "         4,  4,  3,  2,  7,  2,  2,  0,  4,  2,  1,  5,  5,  3,  3,  0,  2,  5,\n",
      "         0,  2,  6,  4,  4,  1,  1,  7,  2, 10,  1,  6,  6,  5,  0,  2,  5,  2,\n",
      "         2,  0,  1,  5,  2,  5,  2,  5,  5,  4,  2,  3,  3,  0,  5,  3,  1,  4,\n",
      "         2,  1,  2,  9, 10,  9,  1,  9,  5,  6,  1,  2,  0,  6,  2,  3,  2,  2,\n",
      "         1,  2,  4,  5,  2,  4,  2,  0,  2,  5,  2,  1,  1,  2,  1,  0, 10,  2,\n",
      "         7,  0, 10,  4,  4,  1,  2,  5,  9,  3,  2,  2,  1,  2,  0,  2,  2,  1,\n",
      "         2,  8,  5,  6,  4,  0,  0,  2,  0, 10,  0,  2,  6,  2,  5,  2,  2,  5,\n",
      "         2,  2,  2,  2,  5,  1,  2,  8,  1,  3,  2,  1,  0,  2,  6,  2,  1,  1,\n",
      "         8,  9,  4,  2,  2,  2,  5, 10,  2,  9,  2,  0,  9,  2,  2,  2,  5,  2,\n",
      "         2,  2,  2,  0,  4,  8,  0,  2,  2,  2,  3,  1,  2,  0,  2, 10,  0,  0,\n",
      "         2,  9,  2,  0,  7,  2,  1,  2,  6,  2,  5,  2,  5,  2,  2,  2,  2,  4,\n",
      "         5,  0,  2,  1,  0,  2,  0,  5,  5,  5,  2,  0, 10,  2,  2,  4,  0,  1,\n",
      "         4,  2,  5,  1,  1,  3,  4,  0,  2,  2,  3,  5,  7,  4,  2,  9,  5,  3,\n",
      "         5,  0,  2,  2,  2,  2,  2,  2,  0,  2,  5,  6,  3,  0,  5,  5,  2,  2,\n",
      "         2,  6,  4,  2,  9, 10,  3,  6,  4,  2,  8,  0,  5, 10,  6,  2,  3,  3,\n",
      "        10,  5,  1,  6,  3,  9, 10,  5,  2,  5,  0,  0,  0,  2,  0,  9,  2, 10,\n",
      "         2,  4,  1,  2,  1,  0,  3,  2,  7,  4,  0,  7,  3,  1,  1,  0,  0,  4,\n",
      "         2,  9,  2,  0,  5,  5,  0,  5, 10,  1, 10,  2,  2,  2,  2,  3,  6,  5,\n",
      "         3,  2,  6,  2,  3,  4,  2,  3,  5,  5,  6,  5,  2,  2,  0,  9,  2,  2,\n",
      "         2,  5,  5,  4,  2,  2,  5,  1,  4,  2,  2,  1,  5,  3,  3,  2,  9,  2,\n",
      "         2,  2,  4,  9,  5,  3,  2,  1,  4,  4,  0,  2,  2,  4,  0, 10,  0,  2,\n",
      "         2,  0, 10,  2,  0,  2,  2,  2,  2,  5,  4,  2,  4,  5,  0,  5,  0,  2,\n",
      "         2,  0,  5,  4,  0,  1,  2,  6,  2,  0,  2, 10, 10, 10,  6,  0,  0,  2,\n",
      "         2,  2,  6,  5,  2,  0,  1,  2,  2,  2,  9,  2,  3,  1,  3,  3,  2,  2,\n",
      "         5,  4,  9,  5, 10,  2,  2,  5,  1,  0,  2,  5,  5,  4,  5,  1,  2,  2,\n",
      "        10,  7, 10,  2, 10,  2,  2,  9,  2,  2,  5,  5,  9,  0,  3,  1,  6,  7,\n",
      "         2,  1,  5,  7,  4,  4,  5,  2,  2,  5,  2,  2, 10,  6,  8, 10,  6,  5,\n",
      "         2,  2,  2,  2,  1,  2,  2,  0,  2,  5,  4,  2,  2,  1,  0,  2,  2,  0,\n",
      "         5,  9,  2,  5,  6,  0,  3,  1,  4,  9,  3,  7,  8,  4,  2,  2,  5,  0,\n",
      "         6,  4,  2,  2, 10,  2,  1,  4,  5,  5,  1,  1,  2,  2,  5,  2,  1,  2,\n",
      "         5,  4, 10, 10,  0,  7,  2,  2,  0, 10,  0,  2,  6,  2,  1,  4, 10,  4,\n",
      "         2,  9,  0,  2,  4,  0,  5,  2,  6,  9,  2,  2,  1,  2,  2,  5,  3,  2,\n",
      "         1,  2,  0,  2,  6,  2,  1,  6,  9,  7,  0,  2,  2,  2, 10,  5, 10,  4,\n",
      "         4,  2,  2,  2,  4,  2,  2, 10,  2,  7,  0,  3,  3,  2,  5,  2,  2,  2,\n",
      "         2,  4,  2,  8,  2,  2,  8,  0,  2,  2,  0,  1,  2,  5,  0,  5,  2,  5,\n",
      "         6,  1, 10,  1,  9,  4,  2,  2,  0, 10,  2,  2,  1,  2,  2,  2,  4,  2,\n",
      "         2, 10,  2, 10, 10,  3,  1,  8,  1,  2,  2,  2,  3, 10,  4,  6,  2,  0,\n",
      "         0,  2,  1,  0,  5,  5,  5,  0,  2,  3,  7,  5,  2,  2,  5,  2,  2,  5,\n",
      "         0,  0,  4,  2, 10,  4,  3,  2,  0,  0,  6,  2,  2,  2,  2,  5,  5,  4,\n",
      "         5,  2,  1,  8,  1,  6,  5,  9,  3,  2,  5,  2,  2,  3,  5,  6,  3,  0,\n",
      "         0,  2,  4,  5,  1,  0,  2,  8,  6,  4, 10,  2,  9,  9,  7,  4,  2,  5,\n",
      "         5, 10,  2,  2,  2,  2,  4,  2,  2,  5])\n",
      "tensor([ 5,  2,  1,  9, 10,  0,  2,  2,  2,  2,  2,  4,  2,  2, 10,  2,  2,  7,\n",
      "         8,  2,  4,  6,  2,  6,  0,  4,  1,  0,  2,  2,  2,  2,  2,  1, 10,  5,\n",
      "         0, 10,  4,  1,  2,  0,  1, 10,  2,  0,  7,  2,  9,  5,  5,  2,  2,  2,\n",
      "         8,  2,  1,  2,  7,  4,  2,  6,  3,  3,  4,  0,  5,  2,  2,  5,  2,  3,\n",
      "         4,  0,  5,  4,  1,  5,  3,  4,  7,  5,  1,  3,  1, 10,  0,  2,  1,  9,\n",
      "         2,  2,  2,  2,  6,  0,  2,  1,  4,  2,  2,  2,  3,  1,  1,  5,  2,  5,\n",
      "         6,  0,  7,  1,  5,  0,  2,  5, 10,  2,  2,  1,  1,  9,  9,  4,  6,  2,\n",
      "         0,  5,  2,  0,  2,  2,  2,  6,  3,  0,  1,  5,  2,  8,  6,  2,  2,  4,\n",
      "         5,  0,  2,  2,  3,  2,  9,  2,  3, 10,  9,  2,  0,  6,  4,  4,  2,  4,\n",
      "         5,  2,  0,  6,  2,  2,  5, 10,  2,  4,  9,  5,  0,  2,  3,  2,  5,  0,\n",
      "         5,  0, 10,  2,  5,  2,  2,  2,  2,  5,  3, 10,  2,  2,  0,  0,  5,  5])\n"
     ]
    }
   ],
   "source": [
    "print(dataAM.edge_type.unique())\n",
    "print(len(dataAM.edge_type.unique()))\n",
    "print(dataAM.node_stores[0].train_y)\n",
    "print(dataAM.node_stores[0].test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NODE TYPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 1666764\n",
      "Number of edges: 11976642\n",
      "Number of classes: 11\n",
      "Number of node features: 0\n",
      "Number of edge features: 0\n",
      "Number of edge types: 266\n",
      "Contains isolated nodes: False\n",
      "Contains self-loops: True\n",
      "Is undirected: True\n",
      "Average node degree: 7.19\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of nodes: {dataAM.num_nodes}')\n",
    "print(f'Number of edges: {dataAM.num_edges}')\n",
    "print(f'Number of classes: {datasetAM.num_classes}')\n",
    "print(f'Number of node features: {dataAM.num_node_features}')\n",
    "print(f'Number of edge features: {dataAM.num_edge_features}')\n",
    "print(f'Number of edge types: {len(dataAM.edge_type.unique())}')\n",
    "\n",
    "print(f'Contains isolated nodes: {dataAM.has_isolated_nodes()}')\n",
    "print(f'Contains self-loops: {dataAM.has_self_loops()}')\n",
    "print(f'Is undirected: {dataAM.is_undirected()}')\n",
    "\n",
    "print(f'Average node degree: {(dataAM.num_edges) / dataAM.num_nodes:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_types = set()\n",
    "for i in range(dataAM.edge_index.shape[1]):\n",
    "    edge_type = dataAM.edge_type[i].detach().numpy().item(0)\n",
    "    edge_types.add(edge_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(node):\n",
    "    return np.random.choice([*edge_types])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0033670033670033673, 0.004761661826172038)\n",
      "[0.010101010101010102, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "for i in range(3):\n",
    "    correct = (dataAM.test_y.numpy() == (np.array([predict(y) for y in dataAM.test_idx]))).sum()\n",
    "    acc.append(correct / len(dataAM.test_idx))\n",
    "\n",
    "\n",
    "print((np.mean(acc), np.std(acc)))\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node Predicion baseline using self made features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = dataAM.edge_index[0].detach().numpy()\n",
    "dst = dataAM.edge_index[1].detach().numpy()\n",
    "edge_type = dataAM.edge_type.detach().numpy()\n",
    "\n",
    "featuresAM = np.zeros((dataAM.num_nodes, 2 * dataAM.num_edge_types))\n",
    "\n",
    "np.add.at(featuresAM, (src, edge_type), 1)\n",
    "np.add.at(featuresAM, (dst, edge_type + dataAM.num_edge_types), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6717171717171717, 0.0)\n",
      "[0.6717171717171717, 0.6717171717171717, 0.6717171717171717]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = featuresAM[dataAM.train_idx]\n",
    "y = dataAM.train_y\n",
    "\n",
    "acc = []\n",
    "for i in range(3):\n",
    "    clf = svm.SVC(kernel='linear')\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    # Predict the labels of the test set\n",
    "    y_pred = clf.predict(featuresAM[dataAM.test_idx])\n",
    "\n",
    "    # Calculate the accuracy of the classifier\n",
    "    accuracy = accuracy_score(dataAM.test_y, y_pred)\n",
    "    acc.append(accuracy)\n",
    "\n",
    "\n",
    "print((np.mean(acc), np.std(acc)))\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- number of edge types influences the model size significantly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataAM.x = torch.Tensor(featuresAM)\n",
    "dataAM.x = torch.ones(dataAM.num_nodes, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/pyg-team/pytorch_geometric/blob/master/examples/rgcn.py\n",
    "\n",
    "# Since our model does only make use of a rather small receptive field, we\n",
    "# filter the graph to only contain the nodes that are at most 2-hop neighbors\n",
    "# away from any training/test node.\n",
    "\n",
    "# from torch_geometric.utils import k_hop_subgraph\n",
    "\n",
    "# node_idx = torch.cat([dataAM.train_idx, dataAM.test_idx], dim=0)\n",
    "# node_idx, edge_index, mapping, edge_mask = k_hop_subgraph(node_idx, 2, dataAM.edge_index, relabel_nodes=True)\n",
    "\n",
    "# dataAM.num_nodes = node_idx.size(0)\n",
    "# dataAM.edge_index = edge_index\n",
    "# dataAM.edge_type = dataAM.edge_type[edge_mask]\n",
    "# dataAM.train_idx = mapping[:dataAM.train_idx.size(0)]\n",
    "# dataAM.test_idx = mapping[dataAM.train_idx.size(0):]\n",
    "# dataAM.x = dataAM.x[node_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "\n",
    "dataAM.y = torch.zeros(dataAM.num_nodes, dtype=torch.long)\n",
    "dataAM.y[dataAM.train_idx] = dataAM.train_y\n",
    "dataAM.y[dataAM.test_idx] = dataAM.test_y\n",
    "\n",
    "am_data = Data(\n",
    "    x=dataAM.x,\n",
    "    edge_index=dataAM.edge_index,\n",
    "    edge_type=dataAM.edge_type,\n",
    "    y=dataAM.y,\n",
    "    train_idx=dataAM.train_idx,\n",
    "    test_idx=dataAM.test_idx\n",
    ")\n",
    "\n",
    "loader = NeighborLoader(\n",
    "    am_data,\n",
    "    num_neighbors=[30,15,10],\n",
    "    batch_size=64,\n",
    "    input_nodes=dataAM.train_idx,\n",
    "    num_workers=1,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "\n",
    "test_loader = NeighborLoader(\n",
    "    am_data,\n",
    "    num_neighbors=[30,15,10],\n",
    "    batch_size=64,\n",
    "    input_nodes=dataAM.test_idx,\n",
    "    num_workers=1,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGCNWrapper(pl.LightningModule):\n",
    "    def __init__(self, in_channels, out_channels, num_relations, num_hidden_layers, norm: nn.Module = nn.Identity, num_bases=None):\n",
    "        super(RGCNWrapper, self).__init__()\n",
    "\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.norms = nn.ModuleList()\n",
    "        self.conv = pyg_nn.FastRGCNConv(in_channels, out_channels, num_relations, num_bases)\n",
    "        for i in range(num_hidden_layers):\n",
    "            self.norms.append(norm())\n",
    "            setattr(self, f'conv{i}', pyg_nn.FastRGCNConv(out_channels, out_channels, num_relations, num_bases))\n",
    "        self.lin = torch.nn.Linear(out_channels, datasetAM.num_classes)\n",
    "    \n",
    "\n",
    "    def forward(self, x, edge_index, edge_type):\n",
    "        x = self.conv(x, edge_index, edge_type)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        for i in range(self.num_hidden_layers):\n",
    "            x = F.dropout(x, training=self.training)\n",
    "            x = getattr(self, f'conv{i}')(x, edge_index, edge_type)\n",
    "            x = self.norms[i](x)\n",
    "            x = F.relu(x)\n",
    "\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "        \n",
    "    def training_step(self, batch):\n",
    "        x, edge_index, edge_type, y = batch.x, batch.edge_index, batch.edge_type, batch.y\n",
    "    \n",
    "        n_id = batch.n_id\n",
    "        idx = [(x in n_id)  for x in batch.train_idx]\n",
    "        out = self(x, edge_index, edge_type)\n",
    "\n",
    "        out_filtered = out[idx]\n",
    "        y_filtered = y[idx]\n",
    "\n",
    "        loss = F.nll_loss(out_filtered, y_filtered)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "        return optimizer\n",
    "\n",
    "logger = WandbLogger(name=\"AM\", project=\"adlg-2\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator='cpu',\n",
    "    max_epochs=2,\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "model_wrapper = RGCNWrapper(dataAM.x.shape[1], 36, dataAM.edge_type.max()+1, 1, num_bases=40)\n",
    "\n",
    "trainer.fit(model_wrapper, loader)\n",
    "\n",
    "test_loader = NeighborLoader(\n",
    "    am_data,\n",
    "    num_neighbors=[30,15,10],\n",
    "    batch_size=64,\n",
    "    input_nodes=dataAM.test_idx,\n",
    "    num_workers=1,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "model_wrapper.eval()\n",
    "\n",
    "preds = []\n",
    "labels = []\n",
    "for batch in test_loader:\n",
    "    x, edge_index, edge_type, y = batch.x, batch.edge_index, batch.edge_type, batch.y\n",
    "    out = model_wrapper(x, edge_index, edge_type)\n",
    "    preds.append(out.argmax(1))\n",
    "    labels.append(y)\n",
    "\n",
    "# get mask of nonzero labels\n",
    "mask = torch.cat(labels).bool()\n",
    "labels = torch.cat(labels)[mask]\n",
    "preds = torch.cat(preds)[mask]\n",
    "\n",
    "correct = float(preds.eq(labels).sum().item())\n",
    "acc = correct / len(labels)\n",
    "\n",
    "print(f'Test Accuracy: {acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model = RGCN(dataAM.x.shape[1], 36, dataAM.edge_type.max()+1, 1)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# if torch.cuda.is_available():\n",
    "#     device = torch.device('cuda')\n",
    "# elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "#     device = torch.device('mps')\n",
    "# else:\n",
    "#     device = torch.device('cpu')\n",
    "\n",
    "# model = model.to(device)\n",
    "# dataAM = dataAM.to(device)\n",
    "\n",
    "# Train the model\n",
    "model.train()\n",
    "for batch in loader:\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    out = model(batch.x, batch.edge_index, batch.edge_type)\n",
    "\n",
    "    loss = criterion(out[:batch.batch_size], batch.train_y[:batch.batch_size])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "# pred = model(dataAM.x, dataAM.edge_index, dataAM.edge_type)\n",
    "# correct = float(pred[dataAM.test_idx].argmax(1).eq(dataAM.test_y).sum().item())\n",
    "# acc = correct / len(dataAM.test_idx)\n",
    "# print(f'Test Accuracy: {acc:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
